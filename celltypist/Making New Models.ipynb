{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db2b1626-a930-4fff-8343-8cc6796c9f77",
   "metadata": {},
   "source": [
    "# Building New Models to Benchmark Against Celltypist\n",
    "In this notebook, I create and train several models based on/using the Celltypist model. I also train these models on a couple different data sets. These models are then tested on the data they were trained on, as well as others in the 'Benchmarking Models' notebook. \n",
    "\n",
    "### Order of Models: \n",
    "0. Train the basic CellTypist model on this data for easy comparison with other models later\n",
    "1. Remove the feature selection from CellTypist (so it only trains the model once)\n",
    "2. Train the model with L1 regularization instead of L2\n",
    "3. Train the model only once with only Cytopus genes\n",
    "4. At the feature selection step, make sure the Cytopus genes are included in the list of top genes\n",
    "\n",
    "### Data Used: \n",
    "CT_45 \n",
    "- CountAdded_PIP_global_object_for_cellxgene.h5ad\n",
    "- models trained on this data are saved as 'ct_model_#.pkl'\n",
    "\n",
    "CT_98\n",
    "- CellTypist_Immune_Reference_v2_count.h5ad\n",
    "- models trained on this data are saved as '98_model_#.pkl'\n",
    "\n",
    "Glasner\n",
    "- glasner_etal_globalAnndata_20230112.vHTA.h5ad + annotations from 'ad_endo_LS_20211026.results.h5ad', ad_fib_scranLogNorm_filt_20220113.h5ad', 'glasner_ad_myeloid_celltypist_20230606.h5ad'\n",
    "- models trained on this are saved as 'g_model_#.pkl'\n",
    "\n",
    "COV_PBMC\n",
    "- haniffa21.processed.h5ad\n",
    "- models trained on this are saved as 'COV_model#.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65db09ee-ab3c-4fcc-b697-6458588b8ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/labuser/anaconda3/envs/auto_cell_type/lib/python3.8/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/Users/labuser/anaconda3/envs/auto_cell_type/lib/python3.8/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/Users/labuser/anaconda3/envs/auto_cell_type/lib/python3.8/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/Users/labuser/anaconda3/envs/auto_cell_type/lib/python3.8/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from anndata import AnnData\n",
    "import numpy as np\n",
    "from scipy.sparse import spmatrix\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "import cytopus as cp\n",
    "\n",
    "from typing import Optional, Union\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import celltypist as ct #if its throwing an error with sklearn, install scikit-learn version 1.1.0 & that should fix\n",
    "from celltypist import logger \n",
    "from celltypist.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb19cb13-25d0-46aa-8fc1-76128831334c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Functions \n",
    "From celltypist/train.py with some edits/additions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde944d1-5275-4098-9385-51dbb86b6d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _to_vector(_vector_or_file):\n",
    "    \"\"\"\n",
    "    For internal use. Turn a file into an array.\n",
    "    \"\"\"\n",
    "    if isinstance(_vector_or_file, str):\n",
    "        try:\n",
    "            return pd.read_csv(_vector_or_file, header=None)[0].values\n",
    "        except Exception as e:\n",
    "            raise Exception(\n",
    "                    f\"🛑 {e}\")\n",
    "    else:\n",
    "        return _vector_or_file\n",
    "\n",
    "def _to_array(_array_like) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    For internal use. Turn an array-like object into an array.\n",
    "    \"\"\"\n",
    "    if isinstance(_array_like, pd.DataFrame):\n",
    "        return _array_like.values\n",
    "    elif isinstance(_array_like, spmatrix):\n",
    "        return _array_like.toarray()\n",
    "    elif isinstance(_array_like, np.matrix):\n",
    "        return np.array(_array_like)\n",
    "    elif isinstance(_array_like, np.ndarray):\n",
    "        return _array_like\n",
    "    else:\n",
    "        raise TypeError(\n",
    "                f\"🛑 Please provide a valid array-like object as input\")\n",
    "\n",
    "def _prepare_data(X, labels, genes, transpose) -> tuple:\n",
    "    \"\"\"\n",
    "    For internal use. Prepare data for celltypist training.\n",
    "    \"\"\"\n",
    "    if (X is None) or (labels is None):\n",
    "        raise Exception(\n",
    "                \"🛑 Missing training data and/or training labels. Please provide both arguments\")\n",
    "    if isinstance(X, AnnData) or (isinstance(X, str) and X.endswith('.h5ad')):\n",
    "        adata = sc.read(X) if isinstance(X, str) else X\n",
    "        adata.var_names_make_unique()\n",
    "        if adata.X.min() < 0:\n",
    "            logger.info(\"👀 Detected scaled expression in the input data, will try the .raw attribute\")\n",
    "            try:\n",
    "                indata = adata.raw.X\n",
    "                genes = adata.raw.var_names\n",
    "            except Exception as e:\n",
    "                raise Exception(\n",
    "                        f\"🛑 Fail to use the .raw attribute in the input object. {e}\")\n",
    "        else:\n",
    "            indata = adata.X\n",
    "            genes = adata.var_names\n",
    "        if isinstance(labels, str) and (labels in adata.obs):\n",
    "            labels = adata.obs[labels]\n",
    "        else:\n",
    "            labels = _to_vector(labels)\n",
    "    elif isinstance(X, str) and X.endswith(('.csv', '.txt', '.tsv', '.tab', '.mtx', '.mtx.gz')):\n",
    "        adata = sc.read(X)\n",
    "        if transpose:\n",
    "            adata = adata.transpose()\n",
    "        if X.endswith(('.mtx', '.mtx.gz')):\n",
    "            if genes is None:\n",
    "                raise Exception(\n",
    "                        \"🛑 Missing `genes`. Please provide this argument together with the input mtx file\")\n",
    "            genes = _to_vector(genes)\n",
    "            if len(genes) != adata.n_vars:\n",
    "                raise ValueError(\n",
    "                        f\"🛑 The number of genes provided does not match the number of genes in {X}\")\n",
    "            adata.var_names = np.array(genes)\n",
    "        adata.var_names_make_unique()\n",
    "        if not float(adata.X.max()).is_integer():\n",
    "            logger.warn(f\"⚠️ Warning: the input file seems not a raw count matrix. The trained model may be biased\")\n",
    "        sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "        sc.pp.log1p(adata)\n",
    "        indata = adata.X\n",
    "        genes = adata.var_names\n",
    "        labels = _to_vector(labels)\n",
    "    elif isinstance(X, str):\n",
    "        raise ValueError(\n",
    "                \"🛑 Invalid input. Supported types: .csv, .txt, .tsv, .tab, .mtx, .mtx.gz and .h5ad\")\n",
    "    else:\n",
    "        logger.info(\"👀 The input training data is processed as an array-like object\")\n",
    "        indata = X\n",
    "        if transpose:\n",
    "            indata = indata.transpose()\n",
    "        if isinstance(indata, pd.DataFrame):\n",
    "            genes = indata.columns\n",
    "        else:\n",
    "            if genes is None:\n",
    "                raise Exception(\n",
    "                        \"🛑 Missing `genes`. Please provide this argument together with the input training data\")\n",
    "            genes = _to_vector(genes)\n",
    "        labels = _to_vector(labels)\n",
    "    return indata, labels, genes\n",
    "\n",
    "def _SGDClassifier(indata, labels,\n",
    "                   alpha, max_iter, n_jobs,\n",
    "                   mini_batch, batch_number, batch_size, epochs, balance_cell_type, penalty , **kwargs) -> SGDClassifier:\n",
    "    \"\"\"\n",
    "    For internal use \n",
    "    \n",
    "    ONE NEW ARG\n",
    "    penalty\n",
    "        allows to user specify what type of regularization\n",
    "    \"\"\"\n",
    "    classifier = SGDClassifier(loss = 'log', penalty = penalty, alpha = alpha, max_iter = max_iter, n_jobs = n_jobs, **kwargs)\n",
    "    if not mini_batch:\n",
    "        logger.info(f\"🏋️ Training data using SGD logistic regression\")\n",
    "        if (len(labels) > 100000) and (indata.shape[1] > 10000):\n",
    "            logger.warn(f\"⚠️ Warning: it may take a long time to train this dataset with {len(labels)} cells and {indata.shape[1]} genes, try to downsample cells and/or restrict genes to a subset (e.g., hvgs)\")\n",
    "        classifier.fit(indata, labels)\n",
    "    else:\n",
    "        logger.info(f\"🏋️ Training data using mini-batch SGD logistic regression\")\n",
    "        no_cells = len(labels)\n",
    "        if no_cells < 10000:\n",
    "            logger.warn(f\"⚠️ Warning: the number of cells ({no_cells}) is not big enough to conduct a proper mini-batch training. You may consider using traditional SGD classifier (mini_batch = False)\")\n",
    "        if no_cells <= batch_size:\n",
    "            raise ValueError(\n",
    "                    f\"🛑 Number of cells ({no_cells}) is fewer than the batch size ({batch_size}). Decrease `batch_size`, or use SGD directly (mini_batch = False)\")\n",
    "        no_cells_sample = min([batch_number*batch_size, no_cells])\n",
    "        starts = np.arange(0, no_cells_sample, batch_size)\n",
    "        if balance_cell_type:\n",
    "            celltype_freq = np.unique(labels, return_counts = True)\n",
    "            len_celltype = len(celltype_freq[0])\n",
    "            mapping = pd.Series(1 / (celltype_freq[1]*len_celltype), index = celltype_freq[0])\n",
    "            p = mapping[labels].values\n",
    "        for epoch in range(1, (epochs+1)):\n",
    "            logger.info(f\"⏳ Epochs: [{epoch}/{epochs}]\")\n",
    "            if not balance_cell_type:\n",
    "                sampled_cell_index = np.random.choice(no_cells, no_cells_sample, replace = False)\n",
    "            else:\n",
    "                sampled_cell_index = np.random.choice(no_cells, no_cells_sample, replace = False, p = p)\n",
    "            for start in starts:\n",
    "                classifier.partial_fit(indata[sampled_cell_index[start:start+batch_size]], labels[sampled_cell_index[start:start+batch_size]], classes = np.unique(labels))\n",
    "    return classifier\n",
    "\n",
    "def train_1(X = None,\n",
    "          labels: Optional[Union[str, list, tuple, np.ndarray, pd.Series, pd.Index]] = None,\n",
    "          genes: Optional[Union[str, list, tuple, np.ndarray, pd.Series, pd.Index]] = None,\n",
    "          transpose_input: bool = False,\n",
    "          with_mean: bool = True,\n",
    "          check_expression: bool = True,\n",
    "          #LR param\n",
    "          C: float = 1.0, solver: Optional[str] = None, max_iter: Optional[int] = None, n_jobs: Optional[int] = None,\n",
    "          #SGD param\n",
    "          use_SGD: bool = False, alpha: float = 0.0001,\n",
    "          #mini-batch\n",
    "          mini_batch: bool = False, batch_number: int = 100, batch_size: int = 1000, epochs: int = 10, balance_cell_type: bool = False,\n",
    "          #feature selection\n",
    "          feature_selection: bool = False, top_genes: int = 300, use_cytopus: bool = False, cyto_genes: Optional[np.ndarray] = None,\n",
    "          #description\n",
    "          date: str = '', details: str = '', url: str = '', source: str = '', version: str = '',\n",
    "          #penalty\n",
    "          penalty: str = 'l2',\n",
    "          #other param\n",
    "          **kwargs) -> Model: \n",
    "    \"\"\"\n",
    "    Train a celltypist model using mini-batch (optional) logistic classifier with a global solver or stochastic gradient descent (SGD) learning. \n",
    "    A version of the celltypist fxn train that adds some additional choices/functions \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X\n",
    "        Path to the input count matrix (supported types are csv, txt, tsv, tab and mtx) or AnnData (h5ad).\n",
    "        Also accepts the input as an :class:`~anndata.AnnData` object, or any array-like objects already loaded in memory.\n",
    "        See `check_expression` for detailed format requirements.\n",
    "        A cell-by-gene format is desirable (see `transpose_input` for more information).\n",
    "    labels\n",
    "        Path to the file containing cell type label per line corresponding to the cells in `X`.\n",
    "        Also accepts any list-like objects already loaded in memory (such as an array).\n",
    "        If `X` is specified as an AnnData, this argument can also be set as a column name from cell metadata.\n",
    "    genes\n",
    "        Path to the file containing one gene per line corresponding to the genes in `X`.\n",
    "        Also accepts any list-like objects already loaded in memory (such as an array).\n",
    "        Note `genes` will be extracted from `X` where possible (e.g., `X` is an AnnData or data frame).\n",
    "    transpose_input\n",
    "        Whether to transpose the input matrix. Set to `True` if `X` is provided in a gene-by-cell format.\n",
    "        (Default: `False`)\n",
    "    with_mean\n",
    "        Whether to subtract the mean values during data scaling. Setting to `False` can lower the memory usage when the input is a sparse matrix but may slightly reduce the model performance.\n",
    "        (Default: `True`)\n",
    "    check_expression\n",
    "        Check whether the expression matrix in the input data is supplied as required.\n",
    "        Except the case where a path to the raw count table file is specified, all other inputs for `X` should be in log1p normalized expression to 10000 counts per cell.\n",
    "        Set to `False` if you want to train the data regardless of the expression formats.\n",
    "        (Default: `True`)\n",
    "    C\n",
    "        Inverse of L2 regularization strength for traditional logistic classifier. A smaller value can possibly improve model generalization while at the cost of decreased accuracy.\n",
    "        This argument is ignored if SGD learning is enabled (`use_SGD = True`).\n",
    "        (Default: 1.0)\n",
    "    solver\n",
    "        Algorithm to use in the optimization problem for traditional logistic classifier.\n",
    "        The default behavior is to choose the solver according to the size of the input data.\n",
    "        This argument is ignored if SGD learning is enabled (`use_SGD = True`).\n",
    "    max_iter\n",
    "        Maximum number of iterations before reaching the minimum of the cost function.\n",
    "        Try to decrease `max_iter` if the cost function does not converge for a long time.\n",
    "        This argument is for both traditional and SGD logistic classifiers, and will be ignored if mini-batch SGD training is conducted (`use_SGD = True` and `mini_batch = True`).\n",
    "        Default to 200, 500, and 1000 for large (>500k cells), medium (50-500k), and small (<50k) datasets, respectively.\n",
    "    n_jobs\n",
    "        Number of CPUs used. Default to one CPU. `-1` means all CPUs are used.\n",
    "        This argument is for both traditional and SGD logistic classifiers.\n",
    "    use_SGD\n",
    "        Whether to implement SGD learning for the logistic classifier.\n",
    "        (Default: `False`)\n",
    "    alpha\n",
    "        L2 regularization strength for SGD logistic classifier. A larger value can possibly improve model generalization while at the cost of decreased accuracy.\n",
    "        This argument is ignored if SGD learning is disabled (`use_SGD = False`).\n",
    "        (Default: 0.0001)\n",
    "    mini_batch\n",
    "        Whether to implement mini-batch training for the SGD logistic classifier.\n",
    "        Setting to `True` may improve the training efficiency for large datasets (for example, >100k cells).\n",
    "        This argument is ignored if SGD learning is disabled (`use_SGD = False`).\n",
    "        (Default: `False`)\n",
    "    batch_number\n",
    "        The number of batches used for training in each epoch. Each batch contains `batch_size` cells.\n",
    "        For datasets which cannot be binned into `batch_number` batches, all batches will be used.\n",
    "        This argument is relevant only if mini-batch SGD training is conducted (`use_SGD = True` and `mini_batch = True`).\n",
    "        (Default: 100)\n",
    "    batch_size\n",
    "        The number of cells within each batch.\n",
    "        This argument is relevant only if mini-batch SGD training is conducted (`use_SGD = True` and `mini_batch = True`).\n",
    "        (Default: 1000)\n",
    "    epochs\n",
    "        The number of epochs for the mini-batch training procedure.\n",
    "        The default values of `batch_number`, `batch_size`, and `epochs` together allow observing ~10^6 training cells.\n",
    "        This argument is relevant only if mini-batch SGD training is conducted (`use_SGD = True` and `mini_batch = True`).\n",
    "        (Default: 10)\n",
    "    balance_cell_type\n",
    "        Whether to balance the cell type frequencies in mini-batches during each epoch.\n",
    "        Setting to `True` will sample rare cell types with a higher probability, ensuring close-to-even cell type distributions in mini-batches.\n",
    "        This argument is relevant only if mini-batch SGD training is conducted (`use_SGD = True` and `mini_batch = True`).\n",
    "        (Default: `False`)\n",
    "    feature_selection\n",
    "        Whether to perform two-pass data training where the first round is used for selecting important features/genes using SGD learning.\n",
    "        If `True`, the training time will be longer.\n",
    "        (Default: `False`)\n",
    "    top_genes\n",
    "        The number of top genes selected from each class/cell-type based on their absolute regression coefficients.\n",
    "        The final feature set is combined across all classes (i.e., union).\n",
    "        (Default: 300)\n",
    "    date\n",
    "        Free text of the date of the model. Default to the time when the training is completed.\n",
    "    details\n",
    "        Free text of the description of the model.\n",
    "    url\n",
    "        Free text of the (possible) download url of the model.\n",
    "    source\n",
    "        Free text of the source (publication, database, etc.) of the model.\n",
    "    version\n",
    "        Free text of the version of the model.\n",
    "    **kwargs\n",
    "        Other keyword arguments passed to :class:`~sklearn.linear_model.LogisticRegression` (`use_SGD = False`) or :class:`~sklearn.linear_model.SGDClassifier` (`use_SGD = True`).\n",
    "        \n",
    "    THREE NEW PARAMETERS: \n",
    "    penalty\n",
    "        Which regularization method to use \n",
    "        (Default: \"l2\")\n",
    "    use_cytopus \n",
    "        Whether to confirm if cytopus genes are included in feature_selection (they are added if not)\n",
    "        This argument is relevant only if feature selection happens (`feature_selection = True`) \n",
    "        (Default: False)\n",
    "    cyto_genes\n",
    "        List of gene names from ctyopus cell identities dictionary\n",
    "        This argument is relevant only if feature selection with cytopus genes happens (`feature_selection = True` and `use_cytopus = True`) \n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    :class:`~celltypist.models.Model`\n",
    "        An instance of the :class:`~celltypist.models.Model` trained by celltypist.\n",
    "    \"\"\"\n",
    "    #prepare\n",
    "    logger.info(\"🍳 Preparing data before training\")\n",
    "    indata, labels, genes = _prepare_data(X, labels, genes, transpose_input)\n",
    "    if isinstance(indata, pd.DataFrame):\n",
    "        indata = indata.values\n",
    "    elif with_mean and isinstance(indata, spmatrix):\n",
    "        indata = indata.toarray()\n",
    "    labels = np.array(labels)\n",
    "    genes = np.array(genes)\n",
    "    #check\n",
    "    ##NEED TO CHANGE 10000 TO MEDIAN AMOUNT \n",
    "    if check_expression and (np.abs(np.expm1(indata[0]).sum()-10000) > 1):\n",
    "        raise ValueError(\n",
    "                \"🛑 Invalid expression matrix, expect log1p normalized expression to 10000 counts per cell\")\n",
    "    if len(labels) != indata.shape[0]:\n",
    "        raise ValueError(\n",
    "                f\"🛑 Length of training labels ({len(labels)}) does not match the number of input cells ({indata.shape[0]})\")\n",
    "    if len(genes) != indata.shape[1]:\n",
    "        raise ValueError(\n",
    "                f\"🛑 The number of genes ({len(genes)}) provided does not match the number of genes in the training data ({indata.shape[1]})\")\n",
    "    #filter\n",
    "    flag = indata.sum(axis = 0) == 0\n",
    "    if isinstance(flag, np.matrix):\n",
    "        flag = flag.A1\n",
    "    if flag.sum() > 0:\n",
    "        logger.info(f\"✂️ {flag.sum()} non-expressed genes are filtered out\")\n",
    "        #indata = indata[:, ~flag]\n",
    "        genes = genes[~flag]\n",
    "    #report data stats\n",
    "    logger.info(f\"🔬 Input data has {indata.shape[0]} cells and {(~flag).sum()} genes\")\n",
    "    #scaler\n",
    "    logger.info(f\"⚖️ Scaling input data\")\n",
    "    scaler = StandardScaler(with_mean = with_mean)\n",
    "    indata = scaler.fit_transform(indata[:, ~flag] if flag.sum() > 0 else indata)\n",
    "    indata[indata > 10] = 10\n",
    "    #sklearn (Cython) does not support very large sparse matrices for the time being\n",
    "    if isinstance(indata, spmatrix) and ((indata.indices.dtype == 'int64') or (indata.indptr.dtype == 'int64')):\n",
    "        indata = indata.toarray()\n",
    "    #max_iter\n",
    "    if max_iter is None:\n",
    "        if indata.shape[0] < 50000:\n",
    "            max_iter = 1000\n",
    "        elif indata.shape[0] < 500000:\n",
    "            max_iter = 500\n",
    "        else:\n",
    "            max_iter = 200\n",
    "    #classifier\n",
    "    if use_SGD or feature_selection:\n",
    "        classifier = _SGDClassifier(indata = indata, labels = labels, alpha = alpha, max_iter = max_iter, n_jobs = n_jobs, mini_batch = mini_batch, batch_number = batch_number, batch_size = batch_size, epochs = epochs, balance_cell_type = balance_cell_type, penalty = penalty, **kwargs)\n",
    "    else:\n",
    "        classifier = _LRClassifier(indata = indata, labels = labels, C = C, solver = solver, max_iter = max_iter, n_jobs = n_jobs, **kwargs)\n",
    "    #feature selection -> new classifier and scaler\n",
    "    if feature_selection:\n",
    "        logger.info(f\"🔎 Selecting features\")\n",
    "        if len(genes) <= top_genes:\n",
    "            raise ValueError(\n",
    "                    f\"🛑 The number of genes ({len(genes)}) is fewer than the `top_genes` ({top_genes}). Unable to perform feature selection\")\n",
    "        gene_index = np.argpartition(np.abs(classifier.coef_), -top_genes, axis = 1)[:, -top_genes:]\n",
    "        gene_index = np.unique(gene_index)\n",
    "        if use_cytopus: \n",
    "            logger.info(f\"🧬 {len(gene_index)} features are selected pre cytopus\")\n",
    "            #confirming that all cytopus genes are in the top genes used in feature selection\n",
    "            #first get a list of all the indexs of cyto_genes \n",
    "            ct_gene_index = []\n",
    "            for x in cyto_genes:\n",
    "                if x in genes: \n",
    "                    idx = np.where(genes==x)[0][0]\n",
    "                    ct_gene_index.append(idx)\n",
    "            for x in ct_gene_index: \n",
    "                if x not in gene_index: \n",
    "                    gene_index = np.append(gene_index, x)\n",
    "            gene_index = np.unique(gene_index)\n",
    "            logger.info(f\"🧬 {len(gene_index)} features are selected after cytopus\")\n",
    "        else:\n",
    "            logger.info(f\"🧬 {len(gene_index)} features are selected\")\n",
    "        genes = genes[gene_index]\n",
    "        #indata = indata[:, gene_index]\n",
    "        logger.info(f\"🏋️ Starting the second round of training\")\n",
    "        if use_SGD:\n",
    "            classifier = _SGDClassifier(indata = indata[:, gene_index], labels = labels, alpha = alpha, max_iter = max_iter, n_jobs = n_jobs, mini_batch = mini_batch, batch_number = batch_number, batch_size = batch_size, epochs = epochs, balance_cell_type = balance_cell_type, penalty = penalty, **kwargs)\n",
    "        else:\n",
    "            classifier = _LRClassifier(indata = indata[:, gene_index], labels = labels, C = C, solver = solver, max_iter = max_iter, n_jobs = n_jobs, **kwargs)\n",
    "        scaler.mean_ = scaler.mean_[gene_index]\n",
    "        scaler.var_ = scaler.var_[gene_index]\n",
    "        scaler.scale_ = scaler.scale_[gene_index]\n",
    "        scaler.n_features_in_ = len(gene_index)\n",
    "    #model finalization\n",
    "    classifier.features = genes\n",
    "    classifier.n_features_in_ = len(genes)\n",
    "    if not date:\n",
    "        date = str(datetime.now())\n",
    "    description = {'date': date, 'details': details, 'url': url, 'source': source, 'version': version, 'number_celltypes': len(classifier.classes_)}\n",
    "    logger.info(f\"✅ Model training done!\")\n",
    "    return Model(classifier, scaler, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b54d1a4-606a-4829-83be-4a8b75992538",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test_split(adata, frac: int = 0.7):\n",
    "    \"\"\"\n",
    "    USING OUTLINE OF CODE FROM trVAE https://doi.org/10.1093/bioinformatics/btaa800\n",
    "    Split AnnData into test and train datasets - maintains annotations\n",
    "    \n",
    "    Params: \n",
    "    adata\n",
    "        Annotated data matrix (Anndata)\n",
    "    frac\n",
    "        Fraction of cells to be used in the training set\n",
    "    \"\"\"\n",
    "    no_idx_train = int(adata.shape[0] * frac)\n",
    "    indices = np.arange(adata.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    train_index = indices[:no_idx_train]\n",
    "    test_index = indices[no_idx_train:]\n",
    "    train = adata[train_index]\n",
    "    test = adata[test_index]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeed9e34-9051-468a-89a8-d6970a456e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fxn to make individual models \n",
    "def make_model(model_ver: int = 0, \n",
    "              X = None,\n",
    "              labels: Optional[Union[str, list, tuple, np.ndarray, pd.Series, pd.Index]] = None,\n",
    "              genes: Optional[Union[str, list, tuple, np.ndarray, pd.Series, pd.Index]] = None,\n",
    "              check_expression: bool = False,\n",
    "              cyto_genes: Optional[np.ndarray] = None,\n",
    "              write_loc: str = 'New Models') -> Model: \n",
    "    \"\"\"\n",
    "    mode_ver \n",
    "        Which type of model to make \n",
    "        (Default: 0)\n",
    "    X\n",
    "        Path to the input count matrix (supported types are csv, txt, tsv, tab and mtx) or AnnData (h5ad).\n",
    "        Also accepts the input as an :class:`~anndata.AnnData` object, or any array-like objects already loaded in memory.\n",
    "        See `check_expression` for detailed format requirements.\n",
    "        A cell-by-gene format is desirable (see `transpose_input` for more information).\n",
    "    labels\n",
    "        Path to the file containing cell type label per line corresponding to the cells in `X`.\n",
    "        Also accepts any list-like objects already loaded in memory (such as an array).\n",
    "        If `X` is specified as an AnnData, this argument can also be set as a column name from cell metadata.\n",
    "    genes\n",
    "        Path to the file containing one gene per line corresponding to the genes in `X`.\n",
    "        Also accepts any list-like objects already loaded in memory (such as an array).\n",
    "        Note `genes` will be extracted from `X` where possible (e.g., `X` is an AnnData or data frame).\n",
    "    check_expression\n",
    "        Check whether the expression matrix in the input data is supplied as required by celltypist.\n",
    "        `X` should be in log1p normalized expression to 10000 counts per cell.\n",
    "        (Default: `False`)\n",
    "    cyto_genes\n",
    "        (For model 4) A list of genes to make sure are included in feature selection\n",
    "    write_loc\n",
    "        Where to save the newly made model \n",
    "        (Default: 'New Models' - directory in GitHub)\n",
    "    \"\"\"\n",
    "    if model_ver == 0:\n",
    "        #vanilla celltypist\n",
    "        model = ct.train(X = X, labels = labels, genes = genes, check_expression = check_expression, use_SGD = True, mini_batch = True, balance_cell_type = True, feature_selection = True)\n",
    "    \n",
    "    if model_ver == 1:\n",
    "        #no fs\n",
    "        model = train_1(X = X, labels = labels, genes = genes, check_expression = check_expression, use_SGD = True, mini_batch = True)\n",
    "    \n",
    "    if model_ver == 2:\n",
    "        #L1 reg\n",
    "        model = train_1(X = X, labels = labels, genes = genes, check_expression = check_expression, use_SGD = True, mini_batch = True, feature_selection = True, penalty = \"l1\")\n",
    "    \n",
    "    if model_ver == 3: \n",
    "        #cytopus genes only\n",
    "        model = train_1(X = X, labels = labels, genes = genes, check_expression = check_expression, use_SGD = True, mini_batch = True)\n",
    "    \n",
    "    if model_ver == 4: \n",
    "        #fs with cytopus genes\n",
    "        model = train_1(X = X, labels = labels, genes = genes, check_expression = check_expression, use_SGD = True, mini_batch = True, feature_selection = True, balance_cell_type = True, use_cytopus = True, cyto_genes = cyto_genes)\n",
    "        \n",
    "    model.write(write_loc)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e76e44-b0d6-4935-a60d-c38791ed08a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data\n",
    "Loading cytopus cell type dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9de12f7-d24d-4da4-8eb5-232f3a795151",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnowledgeBase object containing 75 cell types and 201 cellular processes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "G = cp.kb.KnowledgeBase()\n",
    "cell_dict = G.identities\n",
    "\n",
    "#make a list of genes from cytopus dict & remove NaNs\n",
    "#the celltype information doesn't need to be retained since we're applying this gene list to all celltypes\n",
    "cp_genes = []\n",
    "for i in cell_dict.values():\n",
    "    cp_genes.append(i)\n",
    "cp_genes = list(itertools.chain(*cp_genes)) #make flatlist out of LoL\n",
    "cp_genes = [x for x in cp_genes if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c677b0-0a93-4cf4-a5fc-15377389bef9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### CT_45\n",
    "Loading in data from celltypist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f63e36-f202-471e-ac1a-2ba5ca87c997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adatact_45 = ad.read('../../Data/CountAdded_PIP_global_object_for_cellxgene.h5ad') #local location\n",
    "#sc.pp.subsample(adata, n_obs = 75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e511c2ff-b471-4435-b378-779960bceb4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainct_45, testct_45 = train_test_split(adatact_45)\n",
    "indatact_45 = trainct_45.X\n",
    "labelsct_45 = trainct_45.obs[\"Manually_curated_celltype\"]\n",
    "genesct_45 = trainct_45.var_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e95e72-c754-47ba-9c74-3c93778139a1",
   "metadata": {},
   "source": [
    "Making a data table that only includes genes from cytopus (for model 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c896692-1e65-4394-8a17-d96de6ebce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_and_ct_genes_45 = [x for x in cp_genes if x in adatact_45.var_names]\n",
    "cp_and_ct_genes_45 = np.unique(cp_and_ct_genes_45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea0c9110-df45-4cc6-b2d3-932ebf6fc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainct_45_cp = trainct_45[:, cp_and_ct_genes_45]\n",
    "indatact_45_cp = trainct_45_cp.X\n",
    "labelsct_45_cp = trainct_45_cp.obs[\"Manually_curated_celltype\"]\n",
    "genesct_45_cp = trainct_45_cp.var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b4aca0b-d15e-4fec-a933-888abff9e579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainct_45.write_h5ad('../../CT_45_Train.h5ad')\n",
    "testct_45.write_h5ad('../../CT_45_Test.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ec88d-8007-49f5-9805-5e3fbb7f9b28",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CT_98\n",
    "v2 of CellTypist training data that I believe the Immune_All models were trained on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "300fdb77-970d-4318-abe5-393e3038faae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adatact_98 = ad.read('../../Data/CellTypist_Immune_Reference_v2_count.h5ad') #local location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4750d9-3419-460b-b4d4-76218480f42e",
   "metadata": {},
   "source": [
    "This data is not normalized or transformed. In order to get it to a place where we can train the models, we need to normalize the counts from each cell and transform. CellTypist wants data normalized to 10,000 counts per cell. However, it has been shown that this is not the best technique (Ahlmann-Eltze & Huber, 2023). For our models, we will recommend normalizing to the median library size. You can override CellTypist's expected expression by setting the argument 'check_expression' in the train function to False. After normalizing, the standard is to log transform the data with a pseudocount of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "573c9326-808c-48eb-92bf-99df961ef494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#find median library size & normalize to that value\n",
    "lib_size = []\n",
    "for i in range(675607):\n",
    "    col_sum = adatact_98[i].X.sum()\n",
    "    lib_size.append(col_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed7dc3d9-c243-4fc6-812a-a6b22fee124e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "med_ls = np.median(lib_size) #4725\n",
    "#med_ls = 4725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "803b2471-dee1-4c17-b9a6-c2228121c33d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adatact_98, target_sum = med_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2feef0e9-1000-4322-9299-d14ffaa6850e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4725.0913"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adatact_98.X[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c179cfb7-4802-4db7-97b1-959fd7f9bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log transform\n",
    "adatact_98.X= np.log1p(adatact_98.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b44e3ea7-706e-43a1-a702-818da2e46fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08349609375"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that the data looks ok (want this to be less than 1): \n",
    "np.abs(np.expm1(adatact_98.X[0]).sum()-med_ls) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de59a837-6776-430b-90d1-d492cfb17ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainct_98, testct_98 = train_test_split(adatact_98, 0.2)\n",
    "indatact_98 = trainct_98.X\n",
    "labelsct_98 = trainct_98.obs[\"Harmonised_detailed_type\"]\n",
    "genesct_98 = trainct_98.var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68539c05-12be-4077-88bf-2960004d08da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cp_and_ct_genes_98 = [x for x in cp_genes if x in adatact_98.var_names]\n",
    "cp_and_ct_genes_98 = np.unique(cp_and_ct_genes_98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dbfae52-e27b-41b1-897f-262138ac018e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainct_98_cp = trainct_98[:, cp_and_ct_genes_98]\n",
    "indatact_98_cp = trainct_98_cp.X\n",
    "labelsct_98_cp = trainct_98_cp.obs[\"Harmonised_detailed_type\"]\n",
    "genesct_98_cp = trainct_98_cp.var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a7ecaf3-ad4b-4a98-ab88-5f48eadb3bca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainct_98.write_h5ad('../../CT_98_train.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b3295-a69a-472f-bfbc-614e85a74df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testct_98.write_h5ad('../../CT_98_Test.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba8a026-0256-420a-980d-266949a4f397",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Glasner\n",
    "This dataset combines the cell type labels from 4 datasets: the overall coarsely annotated data, finely annotated endothelial cells data, finely annotated fibroblast data, and finely annotated myeloid cell data. The coarse dataset is the \"base\" that the other annotations were added to. Because most immune cell types only have very high level labels, and cytopus only contains information about immune cells, at a with a much high resolution of labels, I won't make models 3 & 4 for this data, which rely on that information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a25cc0b2-1dfa-477f-8f15-1415497397d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata_g = ad.read('../../Data/glasner_etal_globalAnndata_20230112.vHTA.h5ad') #annotations too coarse, local location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05630df0-f89b-495e-8cd3-54f331d07112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata_g.var = adata_g.var.set_index('gene_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16a98828-fd66-43a8-ab1c-744c64461c7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata_g_endo = ad.read('../../Data/ad_endo_LS_20211026.results.h5ad') #local location\n",
    "adata_g_fib = ad.read('../../Data/ad_fib_scranLogNorm_filt_20220113.h5ad') #local location\n",
    "adata_g_myl = ad.read('../../Data/glasner_ad_myeloid_celltypist_20230606.h5ad') #local location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "feda49db-b3d5-4f3d-b7e0-009ef511acba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['B cell', 'Blood Endothelial', 'Epithelial', 'Fibroblast',\n",
       "       'Lymphatic Endothelial', 'Myeloid', 'Neutrophil', 'T/NK'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_g.obs['cell_lineage'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7eddd8eb-2714-4d6d-8c00-60992f141fce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "myl_id = np.where(np.isin(adata_g.obs['cell_lineage'].values, ['Myeloid']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "469d24b1-3f73-4d7d-8ea4-18b914999fb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata_myl = adata_g[myl_id, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "edc92177-f6b2-4c4f-b185-afc605081ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata_myl.obs[\"finer_cell_types\"] = adata_myl.obs[\"cell_lineage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8e23082c-6e47-4fe0-8cf1-dd12a996c1fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = adata_myl[100].obs_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1b5c1e0d-405c-4de5-b2b5-e655a1741809",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1873804341.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[189], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    adata_myl[idx].obs[\"finer_cell_types\"].convert(adata_g_myl[:,myl_idx].obs[\"cell_type\"].values[0]0\u001b[0m\n\u001b[0m                                                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "idx = np.where(adata_myl.obs_names == x)[0][0]\n",
    "myl_idx = np.where(adata_g_myl.obs_names == x)[0][0]\n",
    "adata_myl[idx].obs[\"finer_cell_types\"].convert(adata_g_myl[:,myl_idx].obs[\"cell_type\"].values[0]0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b0e66b92-71f7-4e71-9088-f2d272b2dd62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131302207384859    Myeloid\n",
       "Name: finer_cell_types, dtype: category\n",
       "Categories (1, object): ['Myeloid']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_myl[idx].obs[\"finer_cell_types\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1373ca9-9aa8-495e-9cf0-195b82c1c235",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata_glas = adata_g.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f3b8957c-96a2-4e2c-be54-d949dd5bacc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>histology</th>\n",
       "      <th>Procedure_Type</th>\n",
       "      <th>n_genes_by_counts</th>\n",
       "      <th>total_counts</th>\n",
       "      <th>total_counts_mt</th>\n",
       "      <th>pct_counts_mt</th>\n",
       "      <th>total_counts_ribo</th>\n",
       "      <th>pct_counts_ribo</th>\n",
       "      <th>Phenograph_cluster</th>\n",
       "      <th>sample_number</th>\n",
       "      <th>...</th>\n",
       "      <th>Treatment Status</th>\n",
       "      <th>Tissue Site</th>\n",
       "      <th>tissue</th>\n",
       "      <th>hta_donor_id</th>\n",
       "      <th>organism</th>\n",
       "      <th>disease</th>\n",
       "      <th>development_stage</th>\n",
       "      <th>suspension_type</th>\n",
       "      <th>assay</th>\n",
       "      <th>cell_lineage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231900127291614</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>Resection</td>\n",
       "      <td>8685</td>\n",
       "      <td>73835.0</td>\n",
       "      <td>8166.0</td>\n",
       "      <td>11.059795</td>\n",
       "      <td>10719.0</td>\n",
       "      <td>14.517506</td>\n",
       "      <td>C26</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Treated</td>\n",
       "      <td>L Lower Lung</td>\n",
       "      <td>lung</td>\n",
       "      <td>HTA8_1033</td>\n",
       "      <td>Homo Sapiens</td>\n",
       "      <td>lung adenocarcinoma</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cell</td>\n",
       "      <td>10xV3</td>\n",
       "      <td>Epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226410787924389</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>Resection</td>\n",
       "      <td>8026</td>\n",
       "      <td>70591.0</td>\n",
       "      <td>9432.0</td>\n",
       "      <td>13.361476</td>\n",
       "      <td>14487.0</td>\n",
       "      <td>20.522448</td>\n",
       "      <td>C26</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Treated</td>\n",
       "      <td>L Lower Lung</td>\n",
       "      <td>lung</td>\n",
       "      <td>HTA8_1033</td>\n",
       "      <td>Homo Sapiens</td>\n",
       "      <td>lung adenocarcinoma</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cell</td>\n",
       "      <td>10xV3</td>\n",
       "      <td>Epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230817405816030</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>Resection</td>\n",
       "      <td>8071</td>\n",
       "      <td>68600.0</td>\n",
       "      <td>7666.0</td>\n",
       "      <td>11.174927</td>\n",
       "      <td>11075.0</td>\n",
       "      <td>16.144314</td>\n",
       "      <td>C26</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Treated</td>\n",
       "      <td>L Lower Lung</td>\n",
       "      <td>lung</td>\n",
       "      <td>HTA8_1033</td>\n",
       "      <td>Homo Sapiens</td>\n",
       "      <td>lung adenocarcinoma</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cell</td>\n",
       "      <td>10xV3</td>\n",
       "      <td>Epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134060535339812</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>Resection</td>\n",
       "      <td>7154</td>\n",
       "      <td>61317.0</td>\n",
       "      <td>9181.0</td>\n",
       "      <td>14.973009</td>\n",
       "      <td>10405.0</td>\n",
       "      <td>16.969194</td>\n",
       "      <td>C26</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Treated</td>\n",
       "      <td>L Lower Lung</td>\n",
       "      <td>lung</td>\n",
       "      <td>HTA8_1033</td>\n",
       "      <td>Homo Sapiens</td>\n",
       "      <td>lung adenocarcinoma</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cell</td>\n",
       "      <td>10xV3</td>\n",
       "      <td>Epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165239984178910</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>Resection</td>\n",
       "      <td>7745</td>\n",
       "      <td>61085.0</td>\n",
       "      <td>7914.0</td>\n",
       "      <td>12.955718</td>\n",
       "      <td>8798.0</td>\n",
       "      <td>14.402882</td>\n",
       "      <td>C26</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Treated</td>\n",
       "      <td>L Lower Lung</td>\n",
       "      <td>lung</td>\n",
       "      <td>HTA8_1033</td>\n",
       "      <td>Homo Sapiens</td>\n",
       "      <td>lung adenocarcinoma</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cell</td>\n",
       "      <td>10xV3</td>\n",
       "      <td>Epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201114504612723</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>268</td>\n",
       "      <td>538.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.602231</td>\n",
       "      <td>247.0</td>\n",
       "      <td>45.910782</td>\n",
       "      <td>C6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>Naive</td>\n",
       "      <td>L Upper Lung</td>\n",
       "      <td>lung</td>\n",
       "      <td>HTA8_1020</td>\n",
       "      <td>Homo Sapiens</td>\n",
       "      <td>lung adenocarcinoma</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cell</td>\n",
       "      <td>10xV2</td>\n",
       "      <td>B cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192306984118187</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277</td>\n",
       "      <td>522.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.383142</td>\n",
       "      <td>250.0</td>\n",
       "      <td>47.892719</td>\n",
       "      <td>C6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>Naive</td>\n",
       "      <td>L Upper Lung</td>\n",
       "      <td>lung</td>\n",
       "      <td>HTA8_1020</td>\n",
       "      <td>Homo Sapiens</td>\n",
       "      <td>lung adenocarcinoma</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cell</td>\n",
       "      <td>10xV2</td>\n",
       "      <td>B cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235122055601502</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>259</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>246.0</td>\n",
       "      <td>47.126434</td>\n",
       "      <td>C6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>Naive</td>\n",
       "      <td>L Upper Lung</td>\n",
       "      <td>lung</td>\n",
       "      <td>HTA8_1020</td>\n",
       "      <td>Homo Sapiens</td>\n",
       "      <td>lung adenocarcinoma</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cell</td>\n",
       "      <td>10xV2</td>\n",
       "      <td>B cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160928745512244</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>303</td>\n",
       "      <td>507.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.366864</td>\n",
       "      <td>149.0</td>\n",
       "      <td>29.388559</td>\n",
       "      <td>C6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>Naive</td>\n",
       "      <td>L Upper Lung</td>\n",
       "      <td>lung</td>\n",
       "      <td>HTA8_1020</td>\n",
       "      <td>Homo Sapiens</td>\n",
       "      <td>lung adenocarcinoma</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cell</td>\n",
       "      <td>10xV2</td>\n",
       "      <td>B cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130736333473643</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255</td>\n",
       "      <td>502.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.394422</td>\n",
       "      <td>238.0</td>\n",
       "      <td>47.410358</td>\n",
       "      <td>C6</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>Naive</td>\n",
       "      <td>L Upper Lung</td>\n",
       "      <td>lung</td>\n",
       "      <td>HTA8_1020</td>\n",
       "      <td>Homo Sapiens</td>\n",
       "      <td>lung adenocarcinoma</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cell</td>\n",
       "      <td>10xV2</td>\n",
       "      <td>B cell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82991 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                histology Procedure_Type  n_genes_by_counts  total_counts  \\\n",
       "231900127291614      LUAD      Resection               8685       73835.0   \n",
       "226410787924389      LUAD      Resection               8026       70591.0   \n",
       "230817405816030      LUAD      Resection               8071       68600.0   \n",
       "134060535339812      LUAD      Resection               7154       61317.0   \n",
       "165239984178910      LUAD      Resection               7745       61085.0   \n",
       "...                   ...            ...                ...           ...   \n",
       "201114504612723      LUAD            NaN                268         538.0   \n",
       "192306984118187      LUAD            NaN                277         522.0   \n",
       "235122055601502      LUAD            NaN                259         522.0   \n",
       "160928745512244      LUAD            NaN                303         507.0   \n",
       "130736333473643      LUAD            NaN                255         502.0   \n",
       "\n",
       "                 total_counts_mt  pct_counts_mt  total_counts_ribo  \\\n",
       "231900127291614           8166.0      11.059795            10719.0   \n",
       "226410787924389           9432.0      13.361476            14487.0   \n",
       "230817405816030           7666.0      11.174927            11075.0   \n",
       "134060535339812           9181.0      14.973009            10405.0   \n",
       "165239984178910           7914.0      12.955718             8798.0   \n",
       "...                          ...            ...                ...   \n",
       "201114504612723             14.0       2.602231              247.0   \n",
       "192306984118187              2.0       0.383142              250.0   \n",
       "235122055601502              0.0       0.000000              246.0   \n",
       "160928745512244             12.0       2.366864              149.0   \n",
       "130736333473643              7.0       1.394422              238.0   \n",
       "\n",
       "                 pct_counts_ribo Phenograph_cluster sample_number  ...  \\\n",
       "231900127291614        14.517506                C26             1  ...   \n",
       "226410787924389        20.522448                C26             1  ...   \n",
       "230817405816030        16.144314                C26             1  ...   \n",
       "134060535339812        16.969194                C26             1  ...   \n",
       "165239984178910        14.402882                C26             1  ...   \n",
       "...                          ...                ...           ...  ...   \n",
       "201114504612723        45.910782                 C6            26  ...   \n",
       "192306984118187        47.892719                 C6            26  ...   \n",
       "235122055601502        47.126434                 C6            26  ...   \n",
       "160928745512244        29.388559                 C6            26  ...   \n",
       "130736333473643        47.410358                 C6            26  ...   \n",
       "\n",
       "                Treatment Status   Tissue Site tissue hta_donor_id  \\\n",
       "231900127291614          Treated  L Lower Lung   lung    HTA8_1033   \n",
       "226410787924389          Treated  L Lower Lung   lung    HTA8_1033   \n",
       "230817405816030          Treated  L Lower Lung   lung    HTA8_1033   \n",
       "134060535339812          Treated  L Lower Lung   lung    HTA8_1033   \n",
       "165239984178910          Treated  L Lower Lung   lung    HTA8_1033   \n",
       "...                          ...           ...    ...          ...   \n",
       "201114504612723            Naive  L Upper Lung   lung    HTA8_1020   \n",
       "192306984118187            Naive  L Upper Lung   lung    HTA8_1020   \n",
       "235122055601502            Naive  L Upper Lung   lung    HTA8_1020   \n",
       "160928745512244            Naive  L Upper Lung   lung    HTA8_1020   \n",
       "130736333473643            Naive  L Upper Lung   lung    HTA8_1020   \n",
       "\n",
       "                     organism              disease development_stage  \\\n",
       "231900127291614  Homo Sapiens  lung adenocarcinoma           unknown   \n",
       "226410787924389  Homo Sapiens  lung adenocarcinoma           unknown   \n",
       "230817405816030  Homo Sapiens  lung adenocarcinoma           unknown   \n",
       "134060535339812  Homo Sapiens  lung adenocarcinoma           unknown   \n",
       "165239984178910  Homo Sapiens  lung adenocarcinoma           unknown   \n",
       "...                       ...                  ...               ...   \n",
       "201114504612723  Homo Sapiens  lung adenocarcinoma           unknown   \n",
       "192306984118187  Homo Sapiens  lung adenocarcinoma           unknown   \n",
       "235122055601502  Homo Sapiens  lung adenocarcinoma           unknown   \n",
       "160928745512244  Homo Sapiens  lung adenocarcinoma           unknown   \n",
       "130736333473643  Homo Sapiens  lung adenocarcinoma           unknown   \n",
       "\n",
       "                suspension_type  assay cell_lineage  \n",
       "231900127291614            cell  10xV3   Epithelial  \n",
       "226410787924389            cell  10xV3   Epithelial  \n",
       "230817405816030            cell  10xV3   Epithelial  \n",
       "134060535339812            cell  10xV3   Epithelial  \n",
       "165239984178910            cell  10xV3   Epithelial  \n",
       "...                         ...    ...          ...  \n",
       "201114504612723            cell  10xV2       B cell  \n",
       "192306984118187            cell  10xV2       B cell  \n",
       "235122055601502            cell  10xV2       B cell  \n",
       "160928745512244            cell  10xV2       B cell  \n",
       "130736333473643            cell  10xV2       B cell  \n",
       "\n",
       "[82991 rows x 29 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_g.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581bb5c-3947-4d0e-a735-d4a0cf09c5c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finer_cell_types = []\n",
    "orig_cell_types = [] \n",
    "for x in adata_g.obs_names:\n",
    "    g_idx = np.where(adata_g.obs_names == x)[0][0]\n",
    "    orig_cell_types.append(adata_glas[g_idx].obs[\"cell_lineage\"].values[0])\n",
    "    if x in adata_g_endo.obs_names:\n",
    "        endo_idx = np.where(adata_g_endo.obs_names == x)[0][0]\n",
    "        finer_cell_types.append(adata_g_endo[:,endo_idx].obs[\"granular_cell_type\"].values[0])\n",
    "    elif x in adata_g_myl.obs_names:\n",
    "        myl_idx = np.where(adata_g_myl.obs_names == x)[0][0]\n",
    "        finer_cell_types.append(adata_g_myl[myl_idx].obs[\"cell_type\"].values[0])\n",
    "    if x in adata_g_fib.obs_names:\n",
    "        fib_idx = np.where(adata_g_fib.obs_names == x)[0][0]\n",
    "        finer_cell_types.append(adata_g_fib[fib_idx].obs[\"granular_cell_type\"].values[0])\n",
    "    else:\n",
    "        finer_cell_types.append(adata_glas[g_idx].obs[\"cell_lineage\"].values[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319cc521-e94b-496b-83db-44c7178b69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_glas.obs[\"finer_cell_types\"] = finer_cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ba81601c-8e47-47f4-a027-977915d48be7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = adata_g_endo[].obs_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "55581448-721e-4469-aed9-702c3e56be76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'130754464836510'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in adata_g.obs_names:\n",
    "    g_idx = np.where(adata_g.obs_names == x)[0][0]\n",
    "    if x in adata_g_endo.obs_names:\n",
    "        endo_idx = np.where(adata_g_endo.obs_names == x)[0][0]\n",
    "        append adata_g_endo[:,endo_idx].obs[\"granular_cell_type\"].values[0]\n",
    "    elif x in adata_g_myl.obs_names:\n",
    "        myl_idx = np.where(adata_g_myl.obs_names == x)[0][0]\n",
    "        adata_glas[g_idx].obs[\"finer_cell_types\"] = adata_g_myl[myl_idx].obs[\"cell_type\"].values[0]\n",
    "    if x in adata_g_fib.obs_names:\n",
    "        fib_idx = np.where(adata_g_fib.obs_names == x)[0][0]\n",
    "        adata_glas[g_idx].obs[\"finer_cell_types\"] = adata_g_fib[fib_idx].obs[\"granular_cell_type\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "11b1594e-9a9b-4c24-9f95-a7aacb3bbacd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   23,    98,   145, ..., 82978, 82980, 82981])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isin(adata_g.obs['cell_lineage'].values, ['Myeloid']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "45fe0947-05f5-4b06-8583-9f5f5eba7787",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['B cell', 'Blood Endothelial', 'Epithelial', 'Fibroblast',\n",
       "       'Lymphatic Endothelial', 'Myeloid', 'Neutrophil', 'T/NK'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_glas.obs['finer_cell_types'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "10174107-deae-49f3-a3ce-8be7e18472ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 82991 × 25441\n",
       "    obs: 'histology', 'Procedure_Type', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'Phenograph_cluster', 'sample_number', 'hta_id', 'Gender', 'Ethnicity', 'Race', 'Smoking Status', 'Pack Years', 'Stage at Dx', 'Tissue Type', 'ProcedureType', 'Treatment Status', 'Tissue Site', 'tissue', 'hta_donor_id', 'organism', 'disease', 'development_stage', 'suspension_type', 'assay', 'cell_lineage', 'finer_cell_types'\n",
       "    var: 'ribo', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable'\n",
       "    uns: 'Phenograph_cluster_colors', 'dendrogram_Phenograph_cluster', 'neighbors', 'pca', 'sample_name_colors', 'umap'\n",
       "    obsm: 'X_pca', 'X_tsne', 'X_umap'\n",
       "    varm: 'PCs'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e47fa38d-1108-4884-88aa-95e7a65c2cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231900127291614           Epithelial\n",
       "226410787924389           Epithelial\n",
       "230817405816030           Epithelial\n",
       "134060535339812           Epithelial\n",
       "165239984178910           Epithelial\n",
       "                         ...        \n",
       "205381642180531              Myeloid\n",
       "131223662811044           Epithelial\n",
       "199823176391923           Epithelial\n",
       "199807089626478           Epithelial\n",
       "230817424596190    Blood Endothelial\n",
       "Name: finer_cell_types, Length: 1000, dtype: category\n",
       "Categories (7, object): ['B cell', 'Blood Endothelial', 'Epithelial', 'Fibroblast', 'Lymphatic Endothelial', 'Myeloid', 'T/NK']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_test.obs['finer_cell_types']  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57519b0-2764-4cf3-a5cd-ef452ff32995",
   "metadata": {
    "tags": []
   },
   "source": [
    "### COV_PBMC\n",
    "The last 192 features in this matrix are antibodies, not genes. The matrix is normalized to the number of counts per gene, excluding the antibodies and since we don't want to include antibodies in our model either, I will be removing those columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "077637b5-1cb4-4144-86ac-270cc381c276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata_COV = ad.read('../../Data/haniffa21.processed.h5ad') #local location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "424e0691-b4e7-47da-9f33-3cd1f6e728e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#remove antibody columns\n",
    "rna_only = [j for j in adata_COV.var_names if 'AB_' not in j]\n",
    "rna_col_id = [adata_COV.var_names.get_loc(j) for j in rna_only]\n",
    "adata_COV = adata_COV[:,np.asarray(rna_col_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46216b3a-27ac-44e4-8851-e1a65704f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_COV = ad.read('../../Data/train_COV.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28127a4c-9178-4196-afaa-9dc582ba6032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_COV, test_COV = train_test_split(adata_COV, 0.2)\n",
    "indata_COV = train_COV.X\n",
    "labels_COV = train_COV.obs[\"full_clustering\"]\n",
    "genes_COV = train_COV.var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd8b7efc-d560-4261-9805-6dd36d54164f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cp_and_ct_genes_COV = [x for x in cp_genes if x in adata_COV.var_names]\n",
    "cp_and_ct_genes_COV = np.unique(cp_and_ct_genes_COV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c2d902-c88b-4adb-b38e-cc1a2f646b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_COV_cp = train_COV[:, cp_and_ct_genes_COV]\n",
    "indata_COV_cp = train_COV_cp.X\n",
    "labels_COV_cp = train_COV_cp.obs[\"full_clustering\"]\n",
    "genes_COV_cp = train_COV_cp.var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94a249cc-4310-4d3c-834c-b0d6b1c57f24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_COV.write('../../Data/train_COV.h5ad')\n",
    "test_COV.write('../../Data/test_COV.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddc9b806-4df9-41cb-bc2f-011875baeab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_COV_cp = test_COV[:, cp_and_ct_genes_COV]\n",
    "test_COV_cp.write('../../test_COV_cp.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbf6c97-627a-453b-9793-63d6b4d7dfcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986ab5d5-abcd-41af-a632-1d8fcf77c270",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model 0\n",
    "Retrain basic celltypist model on this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4183407f-0c50-45f2-9988-54884c353d12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ct = make_model(model_ver = 0, X = indatact_45, labels = labelsct_45, genes = genesct_45, check_expression = True, write_loc = 'New Models/CT_45 Models/ct_model_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c607e53-53db-42b1-afb8-a78f1b7de1db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ct_98 = make_model(model_ver = 0, X = indatact_98, labels = labelsct_98, genes = genesct_98, write_loc = 'New Models/CT_98 Models/98_model_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "254020fa-599d-45df-bc43-cfe7de35a361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🍳 Preparing data before training\n",
      "👀 The input training data is processed as an array-like object\n",
      "✂️ 1179 non-expressed genes are filtered out\n",
      "🔬 Input data has 129473 cells and 23558 genes\n",
      "⚖️ Scaling input data\n",
      "🏋️ Training data using mini-batch SGD logistic regression\n",
      "⏳ Epochs: [1/10]\n",
      "⏳ Epochs: [2/10]\n",
      "⏳ Epochs: [3/10]\n",
      "⏳ Epochs: [4/10]\n",
      "⏳ Epochs: [5/10]\n",
      "⏳ Epochs: [6/10]\n",
      "⏳ Epochs: [7/10]\n",
      "⏳ Epochs: [8/10]\n",
      "⏳ Epochs: [9/10]\n",
      "⏳ Epochs: [10/10]\n",
      "🔎 Selecting features\n",
      "🧬 4716 features are selected\n",
      "🏋️ Starting the second round of training\n",
      "🏋️ Training data using mini-batch SGD logistic regression\n",
      "⏳ Epochs: [1/10]\n",
      "⏳ Epochs: [2/10]\n",
      "⏳ Epochs: [3/10]\n",
      "⏳ Epochs: [4/10]\n",
      "⏳ Epochs: [5/10]\n",
      "⏳ Epochs: [6/10]\n",
      "⏳ Epochs: [7/10]\n",
      "⏳ Epochs: [8/10]\n",
      "⏳ Epochs: [9/10]\n",
      "⏳ Epochs: [10/10]\n",
      "✅ Model training done!\n"
     ]
    }
   ],
   "source": [
    "model_COV = make_model(model_ver = 0, X = indata_COV, labels = labels_COV, genes = genes_COV, write_loc = 'New Models/COV_PBMC Models/COV_model_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d3f56-e050-4b81-bc56-134e5d6cf20f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model 1\n",
    "Train only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a018fd-c3af-45ec-9db4-6028c2f230fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nofs = make_model(model_ver = 1, X = indatact_45, labels = labelsct_45, genes = genesct_45, check_expression = True, write_loc = 'New Models/CT_45 Models/ct_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dfe018-5270-4089-950d-bf805518fc66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_nofs_98 = make_model(model_ver = 1, X = indatact_98, labels = labelsct_98, genes = genesct_98, write_loc = 'New Models/CT_98 Models/98_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d76a068-d985-4622-804e-4c34aa7465e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_nofs_COV = make_model(model_ver = 1, X = indata_COV, labels = labels_COV, genes = genes_COV, write_loc = 'New Models/COV_PBMC Models/COV_model_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986cbd9b-5a79-41f6-9456-03583f3fc027",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model 2\n",
    "Use L1 regularization instead of L2\n",
    "\n",
    "CT_45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a48c24-5db8-4297-bd53-10c6cf8e7541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_L1 = train_1(X = indatact_45, labels = labelsct_45, genes = genesct_45, use_SGD = True, mini_batch = True, feature_selection = True, penalty = \"l1\")\n",
    "#model_L1.write('New Models/CT_45 Models/ct_model_2')\n",
    "model_L1 = make_model(model_ver = 2, X = indatact_45, labels = labelsct_45, genes = genesct_45, check_expression = True, write_loc = 'New Models/CT_45 Models/ct_model_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f7e9c-680f-438b-8a85-a1b27818806d",
   "metadata": {
    "tags": []
   },
   "source": [
    "CT_98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d82bf658-7883-4ce4-bf86-59f7e2d2b930",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🍳 Preparing data before training\n",
      "👀 The input training data is processed as an array-like object\n",
      "✂️ 7040 non-expressed genes are filtered out\n",
      "🔬 Input data has 135121 cells and 31955 genes\n",
      "⚖️ Scaling input data\n",
      "🏋️ Training data using mini-batch SGD logistic regression\n",
      "⏳ Epochs: [1/10]\n",
      "⏳ Epochs: [2/10]\n",
      "⏳ Epochs: [3/10]\n",
      "⏳ Epochs: [4/10]\n",
      "⏳ Epochs: [5/10]\n",
      "⏳ Epochs: [6/10]\n",
      "⏳ Epochs: [7/10]\n",
      "⏳ Epochs: [8/10]\n",
      "⏳ Epochs: [9/10]\n",
      "⏳ Epochs: [10/10]\n",
      "🔎 Selecting features\n",
      "🧬 9121 features are selected\n",
      "🏋️ Starting the second round of training\n",
      "🏋️ Training data using mini-batch SGD logistic regression\n",
      "⏳ Epochs: [1/10]\n",
      "⏳ Epochs: [2/10]\n",
      "⏳ Epochs: [3/10]\n",
      "⏳ Epochs: [4/10]\n",
      "⏳ Epochs: [5/10]\n",
      "⏳ Epochs: [6/10]\n",
      "⏳ Epochs: [7/10]\n",
      "⏳ Epochs: [8/10]\n",
      "⏳ Epochs: [9/10]\n",
      "⏳ Epochs: [10/10]\n",
      "✅ Model training done!\n"
     ]
    }
   ],
   "source": [
    "#model_L1_98 = train_1(X = indatact_98, labels = labelsct_98, genes = genesct_98, check_expression = False, use_SGD = True, mini_batch = True, feature_selection = True, penalty = \"l1\")\n",
    "#model_L1_98.write('New Models/CT_98 Models/98_model_2')\n",
    "model_L1_98 = make_model(model_ver = 2, X = indatact_98, labels = labelsct_98, genes = genesct_98, write_loc = 'New Models/CT_98 Models/98_model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cae9199b-6d2b-4f0f-9fa3-59bad76bbe15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🍳 Preparing data before training\n",
      "👀 The input training data is processed as an array-like object\n",
      "✂️ 1179 non-expressed genes are filtered out\n",
      "🔬 Input data has 129473 cells and 23558 genes\n",
      "⚖️ Scaling input data\n",
      "🏋️ Training data using mini-batch SGD logistic regression\n",
      "⏳ Epochs: [1/10]\n",
      "⏳ Epochs: [2/10]\n",
      "⏳ Epochs: [3/10]\n",
      "⏳ Epochs: [4/10]\n",
      "⏳ Epochs: [5/10]\n",
      "⏳ Epochs: [6/10]\n",
      "⏳ Epochs: [7/10]\n",
      "⏳ Epochs: [8/10]\n",
      "⏳ Epochs: [9/10]\n",
      "⏳ Epochs: [10/10]\n",
      "🔎 Selecting features\n",
      "🧬 5968 features are selected\n",
      "🏋️ Starting the second round of training\n",
      "🏋️ Training data using mini-batch SGD logistic regression\n",
      "⏳ Epochs: [1/10]\n",
      "⏳ Epochs: [2/10]\n",
      "⏳ Epochs: [3/10]\n",
      "⏳ Epochs: [4/10]\n",
      "⏳ Epochs: [5/10]\n",
      "⏳ Epochs: [6/10]\n",
      "⏳ Epochs: [7/10]\n",
      "⏳ Epochs: [8/10]\n",
      "⏳ Epochs: [9/10]\n",
      "⏳ Epochs: [10/10]\n",
      "✅ Model training done!\n"
     ]
    }
   ],
   "source": [
    "#model_L1_COV = train_1(X = indata_COV, labels = labels_COV, genes = genes_COV, check_expression = False, use_SGD = True, mini_batch = True, feature_selection = True, penalty = \"l1\")\n",
    "#model_L1_COV.write('New Models/COV_PBMC Models/COV_model_2')\n",
    "model_L1_COV = make_model(model_ver = 2, X = indata_COV, labels = labels_COV, genes = genes_COV, write_loc = 'New Models/COV_PBMC Models/COV_model_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9576247a-6c45-417e-9469-2d09468afbaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model 3\n",
    "Use only cytopus genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a90b5d-8cf8-4049-9d1e-f27515f25ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_cp = train_1(X = indatact_45_cp, labels = labelsct_45_cp, genes = genesct_45_cp, check_expression = False, use_SGD = True, mini_batch = True)\n",
    "#model_cp.write('New Models/CT_45 Models/ct_model_3')\n",
    "model_ct = make_model(model_ver = 3,X = indatact_45_cp, labels = labelsct_45_cp, genes = genesct_45_cp, check_expression = True, write_loc = 'New Models/CT_45 Models/ct_model_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "314ddbb2-e678-442f-806e-8a3f7c8c0765",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🍳 Preparing data before training\n",
      "👀 The input training data is processed as an array-like object\n",
      "✂️ 1 non-expressed genes are filtered out\n",
      "🔬 Input data has 135121 cells and 303 genes\n",
      "⚖️ Scaling input data\n",
      "🏋️ Training data using mini-batch SGD logistic regression\n",
      "⏳ Epochs: [1/10]\n",
      "⏳ Epochs: [2/10]\n",
      "⏳ Epochs: [3/10]\n",
      "⏳ Epochs: [4/10]\n",
      "⏳ Epochs: [5/10]\n",
      "⏳ Epochs: [6/10]\n",
      "⏳ Epochs: [7/10]\n",
      "⏳ Epochs: [8/10]\n",
      "⏳ Epochs: [9/10]\n",
      "⏳ Epochs: [10/10]\n",
      "✅ Model training done!\n"
     ]
    }
   ],
   "source": [
    "#model_cp_98 = train_1(X = indatact_98_cp, labels = labelsct_98_cp, genes = genesct_98_cp, check_expression = False, use_SGD = True, mini_batch = True)\n",
    "#model_cp_98.write('New Models/CT_98 Models/98_model_3')\n",
    "model_ct = make_model(model_ver = 3, X = indatact_98_cp, labels = labelsct_98_cp, genes = genes98_cp,  write_loc = 'New Models/CT_98 Models/98_model_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9880aa16-4e35-480c-9879-0f8ea7383b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🍳 Preparing data before training\n",
      "👀 The input training data is processed as an array-like object\n",
      "✂️ 2 non-expressed genes are filtered out\n",
      "🔬 Input data has 129473 cells and 298 genes\n",
      "⚖️ Scaling input data\n",
      "🏋️ Training data using mini-batch SGD logistic regression\n",
      "⏳ Epochs: [1/10]\n",
      "⏳ Epochs: [2/10]\n",
      "⏳ Epochs: [3/10]\n",
      "⏳ Epochs: [4/10]\n",
      "⏳ Epochs: [5/10]\n",
      "⏳ Epochs: [6/10]\n",
      "⏳ Epochs: [7/10]\n",
      "⏳ Epochs: [8/10]\n",
      "⏳ Epochs: [9/10]\n",
      "⏳ Epochs: [10/10]\n",
      "✅ Model training done!\n"
     ]
    }
   ],
   "source": [
    "#model_cp_COV = train_1(X = indata_COV_cp, labels = labels_COV_cp, genes = genes_COV_cp, check_expression = False, use_SGD = True, mini_batch = True)\n",
    "#model_cp_COV.write('New Models/COV_PBMC Models/COV_model_3')\n",
    "model_cp_COV = make_model(model_ver = 3, X = indata_COV_cp, labels = labels_COV_cp, genes = genes_COV_cp, write_loc = 'New Models/COV_PBMC Models/COV_model_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1d9dd7-4cd6-47ad-aa36-ef15bab85311",
   "metadata": {},
   "source": [
    "### Model 4\n",
    "Confirm cytopus genes are included in feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9822e-55eb-4878-afcc-7dcc8738ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ct_fs = make_model(model_ver = 4, X = indatact_45, labels = labelsct_45, genes = genesct_45, check_expression = True, cyto_genes = cp_and_ct_genes, write_loc = 'New Models/CT_45 Models/ct_model_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f5353b9-b36b-421e-93f9-61efe263c261",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🍳 Preparing data before training\n",
      "👀 The input training data is processed as an array-like object\n",
      "✂️ 6977 non-expressed genes are filtered out\n",
      "🔬 Input data has 135121 cells and 32018 genes\n",
      "⚖️ Scaling input data\n",
      "🏋️ Training data using mini-batch SGD logistic regression\n",
      "⏳ Epochs: [1/10]\n",
      "⏳ Epochs: [2/10]\n",
      "⏳ Epochs: [3/10]\n",
      "⏳ Epochs: [4/10]\n",
      "⏳ Epochs: [5/10]\n",
      "⏳ Epochs: [6/10]\n",
      "⏳ Epochs: [7/10]\n",
      "⏳ Epochs: [8/10]\n",
      "⏳ Epochs: [9/10]\n",
      "⏳ Epochs: [10/10]\n",
      "🔎 Selecting features\n",
      "🧬 7666 features are selected pre cytopus\n",
      "🧬 7710 features are selected after cytopus\n",
      "🏋️ Starting the second round of training\n",
      "🏋️ Training data using mini-batch SGD logistic regression\n",
      "⏳ Epochs: [1/10]\n",
      "⏳ Epochs: [2/10]\n",
      "⏳ Epochs: [3/10]\n",
      "⏳ Epochs: [4/10]\n",
      "⏳ Epochs: [5/10]\n",
      "⏳ Epochs: [6/10]\n",
      "⏳ Epochs: [7/10]\n",
      "⏳ Epochs: [8/10]\n",
      "⏳ Epochs: [9/10]\n",
      "⏳ Epochs: [10/10]\n",
      "✅ Model training done!\n"
     ]
    }
   ],
   "source": [
    "model_cp_fs_98 = make_model(model_ver = 4, X = indatact_98, labels = labelsct_98, genes = genesct_98, cyto_genes = cp_and_ct_genes_98, write_loc = 'New Models/CT_98 Models/98_model_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c633e5de-892c-4f47-87f9-4440e2da4839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🍳 Preparing data before training\n",
      "👀 The input training data is processed as an array-like object\n",
      "✂️ 1179 non-expressed genes are filtered out\n",
      "🔬 Input data has 129473 cells and 23558 genes\n",
      "⚖️ Scaling input data\n",
      "🏋️ Training data using mini-batch SGD logistic regression\n",
      "⏳ Epochs: [1/10]\n",
      "⏳ Epochs: [2/10]\n",
      "⏳ Epochs: [3/10]\n",
      "⏳ Epochs: [4/10]\n",
      "⏳ Epochs: [5/10]\n",
      "⏳ Epochs: [6/10]\n",
      "⏳ Epochs: [7/10]\n",
      "⏳ Epochs: [8/10]\n",
      "⏳ Epochs: [9/10]\n",
      "⏳ Epochs: [10/10]\n",
      "🔎 Selecting features\n",
      "🧬 4740 features are selected pre cytopus\n",
      "🧬 4832 features are selected after cytopus\n",
      "🏋️ Starting the second round of training\n",
      "🏋️ Training data using mini-batch SGD logistic regression\n",
      "⏳ Epochs: [1/10]\n",
      "⏳ Epochs: [2/10]\n",
      "⏳ Epochs: [3/10]\n",
      "⏳ Epochs: [4/10]\n",
      "⏳ Epochs: [5/10]\n",
      "⏳ Epochs: [6/10]\n",
      "⏳ Epochs: [7/10]\n",
      "⏳ Epochs: [8/10]\n",
      "⏳ Epochs: [9/10]\n",
      "⏳ Epochs: [10/10]\n",
      "✅ Model training done!\n"
     ]
    }
   ],
   "source": [
    "model_cp_fs_COV = make_model(model_ver = 4, X = indata_COV, labels = labels_COV, genes = genes_COV, cyto_genes = cp_and_ct_genes_COV, write_loc = 'New Models/COV_PBMC Models/COV_model_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143cfe87-7b63-48a9-ad21-d36fc5652381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
